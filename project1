import cv2
import numpy as np
import os

# Load the video file from the given path
video_path = r'E:\PictureCollection\New.mp4'  

cap = cv2.VideoCapture(video_path)

# Check if the video file opened successfully
if not cap.isOpened():
    print("Error: Could not open video file.")
    exit()

# Create a directory to store extracted frames
output_dir = r'E:\DIP Assignment'  # Directory where you want to save the frames
os.makedirs(output_dir, exist_ok=True)

# Get video properties for saving the processed video
fourcc = cv2.VideoWriter_fourcc(*'XVID')  # Codec for video writing
fps = cap.get(cv2.CAP_PROP_FPS)           # Frames per second of the video
frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))   # Width of the frames
frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)) # Height of the frames

# Create a VideoWriter object to save the processed video
out = cv2.VideoWriter('output_video.avi', fourcc, fps, (frame_width, frame_height))

# Parameters for detecting features in the video
feature_params = dict(maxCorners=100, qualityLevel=0.3, minDistance=7, blockSize=7)

# Parameters for Lucas-Kanade optical flow (tracking movement)
lk_params = dict(winSize=(15, 15), maxLevel=2, criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))

# Take the first frame from the video and detect corners in it
ret, old_frame = cap.read()
if not ret:
    print("Error: Could not read the first frame.")
    cap.release()
    exit()

# Convert the first frame to grayscale
old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)

# Detect good features to track
p0 = cv2.goodFeaturesToTrack(old_gray, mask=None, **feature_params)

# Create a mask image for drawing lines (to show feature tracking)
mask = np.zeros_like(old_frame)

# Initialize the frame counter
frame_count = 0

while True:
    # Read the next frame from the video
    ret, frame = cap.read()

    # If the frame is not retrieved, break the loop
    if not ret:
        break

    # Convert the current frame to grayscale
    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

    # Calculate optical flow to find movement of features
    p1, st, err = cv2.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params)

    # Select good points where the feature was found in both frames
    good_new = p1[st == 1]
    good_old = p0[st == 1]

    # Draw the tracks (lines and circles) to show movement
    for i, (new, old) in enumerate(zip(good_new, good_old)):
        a, b = new.ravel()  # New point position
        c, d = old.ravel()  # Old point position
        mask = cv2.line(mask, (int(a), int(b)), (int(c), int(d)), (0, 255, 0), 2)  # Convert to int
        frame = cv2.circle(frame, (int(a), int(b)), 5, (0, 0, 255), -1)  # Convert to int

    # Combine the frame with the mask to display the tracked features
    img = cv2.add(frame, mask)

    # Save the current frame as an image file
    frame_filename = f"{output_dir}/frame_{frame_count:04d}.jpg"
    cv2.imwrite(frame_filename, img)

    # Write the frame into the output video
    out.write(img)

    # Update the previous frame and points for the next iteration
    old_gray = frame_gray.copy()
    p0 = good_new.reshape(-1, 1, 2)

    # Display the resulting frame with tracked features
    cv2.imshow('Feature Tracking', img)

    # Increment the frame counter
    frame_count += 1

    # Press 'q' to stop displaying frames
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# Release the video capture and writer, and close any open windows
cap.release()
out.release()
cv2.destroyAllWindows()

print(f"Extracted {frame_count} frames and saved the output video as 'output_video.avi'.")
